{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from openai import OpenAI\n",
    "from llm_humanise_path import get_all_paths, process_mwo_response, get_fewshot_message, process_single_response, initialise_prompts, get_prompt\n",
    "from llm_paraphrase import paraphrase_MWO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\tpaths in object_property_paths\n",
      "567\tpaths in process_agent_paths\n",
      "402\tpaths in process_patient_paths\n",
      "1743\tpaths in state_patient_paths\n",
      "7\tpaths in object_property_state_paths\n",
      "0\tpaths in object_process_state_paths\n",
      "202\tpaths in state_agent_activity_paths\n",
      "44\tpaths in state_agent_patient_paths\n",
      "188\tpaths in process_agent_patient_paths\n",
      "Total number of paths: 3207\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key='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')\n",
    "data = get_all_paths(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same prompt VS Variant prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "path = random.choice(data)\n",
    "base_prompts, instructions = initialise_prompts(client, num_variants=5, num_examples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same prompt\n",
    "def same_prompt():\n",
    "    outputs = []\n",
    "    base_prompt = \"Generate a Maintenance Work Order (MWO) sentence describing the following equipment and undesirable event.\"\n",
    "    instruction = \"The sentence can have a maximum of 8 words.\"\n",
    "    prompt = f\"{base_prompt}\\nEquipment: {path['object_name']}\\nUndesirable Event: {path['event_name']}\\n{instruction}\"\n",
    "    fewshot = get_fewshot_message([base_prompt], [instruction], 1)\n",
    "    message = fewshot + [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=message,\n",
    "                    temperature=0.9,\n",
    "                    top_p=0.9,\n",
    "                    n=5\n",
    "                )\n",
    "\n",
    "    for choice in response.choices:\n",
    "        output = choice.message.content\n",
    "        output = process_single_response(output) \n",
    "        outputs.append(output)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variant prompts\n",
    "def variant_prompt():\n",
    "    outputs = []\n",
    "    fewshot = get_fewshot_message(base_prompts, instructions, 1)\n",
    "    for _ in range(5):\n",
    "        prompt = get_prompt(base_prompts, instructions, path['object_name'], path['event_name'])\n",
    "        message = fewshot + [{\"role\": \"user\", \"content\": prompt}]\n",
    "        response = client.chat.completions.create(\n",
    "                        model=\"gpt-4o-mini\",\n",
    "                        messages=message,\n",
    "                        temperature=0.9,\n",
    "                        top_p=0.9,\n",
    "                        n=1\n",
    "                )\n",
    "\n",
    "        for choice in response.choices:\n",
    "            output = choice.message.content\n",
    "            output = process_single_response(output)\n",
    "            outputs.append(output)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT given same prompt:\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected\n",
      "GPT given variant prompts:\n",
      "- park brake alarm fault detected\n",
      "- park brake shows alarm fault\n",
      "- park brake alarm fault detected\n",
      "- park brake has alarm fault\n",
      "- park brake alarm fault detected\n"
     ]
    }
   ],
   "source": [
    "# Demo\n",
    "same = same_prompt()\n",
    "variant = variant_prompt()\n",
    "\n",
    "print (\"GPT given same prompt:\")\n",
    "for s in same:\n",
    "    print(f\"- {s}\")\n",
    "print (\"GPT given variant prompts:\")\n",
    "for v in variant:\n",
    "    print(f\"- {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique responses for same prompt: 3\n",
      "Number of unique responses for variant prompts: 20\n"
     ]
    }
   ],
   "source": [
    "# Compare diversity over long run\n",
    "same = []\n",
    "variant = []\n",
    "for _ in range(20):\n",
    "    same.extend(same_prompt())\n",
    "    variant.extend(variant_prompt())\n",
    "print (f\"Number of unique responses for same prompt: {len(set(same))}\")\n",
    "print (f\"Number of unique responses for variant prompts: {len(set(variant))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N completions VS N sentences in ONE completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N sentences in ONE completion\n",
    "def n_sentences():\n",
    "    outputs = []\n",
    "    base_prompt = \"Generate 5 different Maintenance Work Order (MWO) sentences describing the following equipment and undesirable event.\"\n",
    "    instruction = \"Each sentence can have a maximum of 8 words.\"\n",
    "    prompt = f\"{base_prompt}\\nEquipment: {path['object_name']}\\nUndesirable Event: {path['event_name']}\\n{instruction}\"\n",
    "    fewshot = get_fewshot_message([base_prompt], [instruction], 5)\n",
    "    message = fewshot + [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=message,\n",
    "                    temperature=0.9,\n",
    "                    top_p=0.9,\n",
    "                    n=1\n",
    "                )\n",
    "\n",
    "    for choice in response.choices:\n",
    "        output = choice.message.content\n",
    "        output = process_mwo_response(output)\n",
    "        for sentence in output:\n",
    "            outputs.append(sentence)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output in N completions:\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected\n",
      "Output within 1 completion:\n",
      "- park brake alarm fault detected\n",
      "- park brake shows alarm fault\n",
      "- alarm fault in park brake system\n",
      "- park brake has alarm fault\n",
      "- park brake is experiencing alarm fault\n"
     ]
    }
   ],
   "source": [
    "# Demo\n",
    "n_completion = same_prompt()\n",
    "n_sentence = n_sentences()\n",
    "\n",
    "print (\"Output in N completions:\")\n",
    "for c in n_completion:\n",
    "    print(f\"- {c}\")\n",
    "print (\"Output within 1 completion:\")\n",
    "for s in n_sentence:\n",
    "    print(f\"- {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique responses for N completions: 3\n",
      "Number of unique responses for ONE completion: 22\n"
     ]
    }
   ],
   "source": [
    "# Compare diversity over long run\n",
    "n_completion = []\n",
    "n_sentence = []\n",
    "for _ in range(20):\n",
    "    n_completion.extend(same_prompt())\n",
    "    n_sentence.extend(n_sentences())\n",
    "print (f\"Number of unique responses for N completions: {len(set(n_completion))}\")\n",
    "print (f\"Number of unique responses for ONE completion: {len(set(n_sentence))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paraphrase VS Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paraphrase\n",
    "def paraphrase():\n",
    "    outputs = []\n",
    "    base_prompt = \"Generate a Maintenance Work Order (MWO) sentence describing the following equipment and undesirable event.\"\n",
    "    instruction = \"The sentence can have a maximum of 8 words.\"\n",
    "    prompt = f\"{base_prompt}\\nEquipment: {path['object_name']}\\nUndesirable Event: {path['event_name']}\\n{instruction}\"\n",
    "    fewshot = get_fewshot_message([base_prompt], [instruction], 1)\n",
    "    message = fewshot + [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=message,\n",
    "                    temperature=0.9,\n",
    "                    top_p=0.9,\n",
    "                    n=1\n",
    "            )\n",
    "\n",
    "    for choice in response.choices:\n",
    "        output = choice.message.content\n",
    "        output = process_single_response(output)\n",
    "        outputs.append(output)\n",
    "\n",
    "    keywords = [path['object_name'], path['event_name']]\n",
    "    paraphrases = paraphrase_MWO(client, output, keywords, 5)\n",
    "    outputs.extend(paraphrases)\n",
    "    outputs = list(set(outputs)) # Remove duplicates\n",
    "    return outputs[:5] # Only return 5 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for Paraphrasing:\n",
      "- park brake alarm fault detected\n",
      "- park brake has an alarm fault identified\n",
      "- the park brake shows an alarm fault\n",
      "- detected an alarm fault in the park brake\n",
      "- an alarm fault in the park brake found\n",
      "Output for Generation:\n",
      "- park brake alarm fault detected\n",
      "- alarm fault in park brake system\n",
      "- park brake has alarm fault\n",
      "- park brake system shows alarm fault\n",
      "- alarm fault present in park brake\n"
     ]
    }
   ],
   "source": [
    "# Demo\n",
    "paraphrases = paraphrase()\n",
    "n_sentence = n_sentences()\n",
    "\n",
    "print (\"Output for Paraphrasing:\")\n",
    "for p in paraphrases:\n",
    "    print(f\"- {p}\")\n",
    "print (\"Output for Generation:\")\n",
    "for s in n_sentence:\n",
    "    print(f\"- {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare diversity over long run\n",
    "paraphrases = []\n",
    "n_sentence = []\n",
    "for _ in range(20):\n",
    "    paraphrases.extend(paraphrase())\n",
    "    n_sentence.extend(n_sentences())\n",
    "print (f\"Number of unique responses for paraphrasing: {len(set(paraphrases))}\")\n",
    "print (f\"Number of unique responses for generation: {len(set(n_sentence))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
