{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allis\\miniconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "from openai import OpenAI\n",
    "from llm_humanise_path import get_all_paths, process_mwo_response, get_fewshot_message, process_single_response, initialise_prompts, get_prompt\n",
    "from llm_paraphrase import paraphrase_MWO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\tpaths in object_property_paths\n",
      "567\tpaths in process_agent_paths\n",
      "402\tpaths in process_patient_paths\n",
      "1743\tpaths in state_patient_paths\n",
      "7\tpaths in object_property_state_paths\n",
      "0\tpaths in object_process_state_paths\n",
      "202\tpaths in state_agent_activity_paths\n",
      "44\tpaths in state_agent_patient_paths\n",
      "188\tpaths in process_agent_patient_paths\n",
      "Total number of paths: 3207\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key='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')\n",
    "data = get_all_paths(valid=True)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load abbreviations dictionary\n",
    "def load_dictionary(file):\n",
    "    dictionary = {}\n",
    "    with open(file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader) # Ignore header\n",
    "        for row in reader:\n",
    "            original = row[0]\n",
    "            variations = row[1]\n",
    "            if original in dictionary:\n",
    "                dictionary[original].append(variations)\n",
    "            else:\n",
    "                dictionary[original] = [variations]\n",
    "    dictionary = dict(sorted(dictionary.items()))\n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same prompt VS Variant prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allis\\miniconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "path = random.choice(data)\n",
    "base_prompts, instructions = initialise_prompts(client, num_variants=5, num_examples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same prompt\n",
    "def same_prompt():\n",
    "    outputs = []\n",
    "    base_prompt = \"Generate a Maintenance Work Order (MWO) sentence describing the following equipment and undesirable event.\"\n",
    "    instruction = \"The sentence can have a maximum of 8 words.\"\n",
    "    prompt = f\"{base_prompt}\\nEquipment: {path['object_name']}\\nUndesirable Event: {path['event_name']}\\n{instruction}\"\n",
    "    fewshot = get_fewshot_message([base_prompt], [instruction], 1)\n",
    "    message = fewshot + [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=message,\n",
    "                    temperature=0.9,\n",
    "                    top_p=0.9,\n",
    "                    n=5\n",
    "                )\n",
    "\n",
    "    for choice in response.choices:\n",
    "        output = choice.message.content\n",
    "        output = process_single_response(output) \n",
    "        outputs.append(output)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variant prompts\n",
    "def variant_prompt():\n",
    "    outputs = []\n",
    "    fewshot = get_fewshot_message(base_prompts, instructions, 1)\n",
    "    for _ in range(5):\n",
    "        prompt = get_prompt(base_prompts, instructions, path['object_name'], path['event_name'])\n",
    "        message = fewshot + [{\"role\": \"user\", \"content\": prompt}]\n",
    "        response = client.chat.completions.create(\n",
    "                        model=\"gpt-4o-mini\",\n",
    "                        messages=message,\n",
    "                        temperature=0.9,\n",
    "                        top_p=0.9,\n",
    "                        n=1\n",
    "                )\n",
    "\n",
    "        for choice in response.choices:\n",
    "            output = choice.message.content\n",
    "            output = process_single_response(output)\n",
    "            outputs.append(output)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT given same prompt:\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected\n",
      "GPT given variant prompts:\n",
      "- park brake alarm fault detected\n",
      "- park brake shows alarm fault\n",
      "- park brake alarm fault detected\n",
      "- park brake has alarm fault\n",
      "- park brake alarm fault detected\n"
     ]
    }
   ],
   "source": [
    "# Demo\n",
    "same = same_prompt()\n",
    "variant = variant_prompt()\n",
    "\n",
    "print (\"GPT given same prompt:\")\n",
    "for s in same:\n",
    "    print(f\"- {s}\")\n",
    "print (\"GPT given variant prompts:\")\n",
    "for v in variant:\n",
    "    print(f\"- {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique responses for same prompt: 3\n",
      "Number of unique responses for variant prompts: 20\n"
     ]
    }
   ],
   "source": [
    "# Compare diversity over long run\n",
    "same = []\n",
    "variant = []\n",
    "for _ in range(20):\n",
    "    same.extend(same_prompt())\n",
    "    variant.extend(variant_prompt())\n",
    "print (f\"Number of unique responses for same prompt: {len(set(same))}\")\n",
    "print (f\"Number of unique responses for variant prompts: {len(set(variant))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N completions VS N sentences in ONE completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N sentences in ONE completion\n",
    "def n_sentences():\n",
    "    outputs = []\n",
    "    base_prompt = \"Generate 5 different Maintenance Work Order (MWO) sentences describing the following equipment and undesirable event.\"\n",
    "    instruction = \"Each sentence can have a maximum of 8 words.\"\n",
    "    prompt = f\"{base_prompt}\\nEquipment: {path['object_name']}\\nUndesirable Event: {path['event_name']}\\n{instruction}\"\n",
    "    fewshot = get_fewshot_message([base_prompt], [instruction], 5)\n",
    "    message = fewshot + [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=message,\n",
    "                    temperature=0.9,\n",
    "                    top_p=0.9,\n",
    "                    n=1\n",
    "                )\n",
    "\n",
    "    for choice in response.choices:\n",
    "        output = choice.message.content\n",
    "        output = process_mwo_response(output)\n",
    "        for sentence in output:\n",
    "            outputs.append(sentence)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output in N completions:\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected\n",
      "Output within 1 completion:\n",
      "- park brake alarm fault detected\n",
      "- park brake shows alarm fault\n",
      "- alarm fault in park brake system\n",
      "- park brake has alarm fault\n",
      "- park brake is experiencing alarm fault\n"
     ]
    }
   ],
   "source": [
    "# Demo\n",
    "n_completion = same_prompt()\n",
    "n_sentence = n_sentences()\n",
    "\n",
    "print (\"Output in N completions:\")\n",
    "for c in n_completion:\n",
    "    print(f\"- {c}\")\n",
    "print (\"Output within 1 completion:\")\n",
    "for s in n_sentence:\n",
    "    print(f\"- {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique responses for N completions: 3\n",
      "Number of unique responses for ONE completion: 22\n"
     ]
    }
   ],
   "source": [
    "# Compare diversity over long run\n",
    "n_completion = []\n",
    "n_sentence = []\n",
    "for _ in range(20):\n",
    "    n_completion.extend(same_prompt())\n",
    "    n_sentence.extend(n_sentences())\n",
    "print (f\"Number of unique responses for N completions: {len(set(n_completion))}\")\n",
    "print (f\"Number of unique responses for ONE completion: {len(set(n_sentence))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paraphrase VS Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paraphrase\n",
    "def paraphrase():\n",
    "    outputs = []\n",
    "    base_prompt = \"Generate a Maintenance Work Order (MWO) sentence describing the following equipment and undesirable event.\"\n",
    "    instruction = \"The sentence can have a maximum of 8 words.\"\n",
    "    prompt = f\"{base_prompt}\\nEquipment: {path['object_name']}\\nUndesirable Event: {path['event_name']}\\n{instruction}\"\n",
    "    fewshot = get_fewshot_message([base_prompt], [instruction], 1)\n",
    "    message = fewshot + [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=message,\n",
    "                    temperature=0.9,\n",
    "                    top_p=0.9,\n",
    "                    n=1\n",
    "            )\n",
    "\n",
    "    for choice in response.choices:\n",
    "        output = choice.message.content\n",
    "        output = process_single_response(output)\n",
    "        outputs.append(output)\n",
    "\n",
    "    keywords = [path['object_name'], path['event_name']]\n",
    "    paraphrases = paraphrase_MWO(client, output, keywords, 5)\n",
    "    outputs.extend(paraphrases)\n",
    "    outputs = list(set(outputs)) # Remove duplicates\n",
    "    return outputs[:5] # Only return 5 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for Paraphrasing:\n",
      "- park brake alarm fault detected\n",
      "- park brake has an alarm fault identified\n",
      "- the park brake shows an alarm fault\n",
      "- detected an alarm fault in the park brake\n",
      "- an alarm fault in the park brake found\n",
      "Output for Generation:\n",
      "- park brake alarm fault detected\n",
      "- alarm fault in park brake system\n",
      "- park brake has alarm fault\n",
      "- park brake system shows alarm fault\n",
      "- alarm fault present in park brake\n"
     ]
    }
   ],
   "source": [
    "# Demo\n",
    "paraphrases = paraphrase()\n",
    "n_sentence = n_sentences()\n",
    "\n",
    "print (\"Output for Paraphrasing:\")\n",
    "for p in paraphrases:\n",
    "    print(f\"- {p}\")\n",
    "print (\"Output for Generation:\")\n",
    "for s in n_sentence:\n",
    "    print(f\"- {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique responses for paraphrasing: 49\n",
      "Number of unique responses for generation: 20\n"
     ]
    }
   ],
   "source": [
    "# Compare diversity over long run\n",
    "paraphrases = []\n",
    "n_sentence = []\n",
    "for _ in range(20):\n",
    "    paraphrases.extend(paraphrase())\n",
    "    n_sentence.extend(n_sentences())\n",
    "print (f\"Number of unique responses for paraphrasing: {len(set(paraphrases))}\")\n",
    "print (f\"Number of unique responses for generation: {len(set(n_sentence))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Paraphraser Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_paraphrase(tokenizer, model, sentences):\n",
    "    outputs = {}\n",
    "    for sentence in sentences:\n",
    "        batch = tokenizer([sentence],truncation=True,padding='longest',max_length=8, return_tensors=\"pt\")\n",
    "        translated = model.generate(**batch,max_length=15,num_beams=5, num_return_sequences=5, temperature=1.5)\n",
    "        output = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "        outputs[sentence] = output\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BART Outputs:\n",
      "park brake alarm fault detected:\n",
      "- park brake alarm fault detected\n",
      "- park brake fault detected\n",
      "- park brake alarm fault fault detected\n",
      "- park brake alarm fault found\n",
      "- park brake alarm detected\n",
      "alarm fault in park brake system:\n",
      "- alarm fault in park brake\n",
      "- alarm fault in park brakes\n",
      "- alarm fault in park car\n",
      "- alarm fault in park assist\n",
      "- alarm fault in park system\n",
      "park brake has alarm fault:\n",
      "- park brake has alarm fault\n",
      "- park brake has warning light fault\n",
      "- park brake has alarm problem\n",
      "- park brake has alarm fault may cause\n",
      "- park brake has alarm fault may be\n",
      "park brake system shows alarm fault:\n",
      "- park brake system shows alarm fault\n",
      "- park brake system shows alarm fault in California\n",
      "- park brake system shows alarm fault in Florida\n",
      "- park brake system shows alarm fault in China\n",
      "- park brake system shows alarm fault in car\n",
      "alarm fault present in park brake:\n",
      "- alarm may be present in park\n",
      "- alarm fault present in South Korea\n",
      "- alarm fault present in South Africa\n",
      "- alarm fault present in US nuclear plant\n",
      "- alarm fault present in US\n",
      "The boy is walking happily on the street:\n",
      "- The boy is walking happily on\n",
      "- The boy is walking happily through the woods.\n",
      "- The boy is walking happily through the forest.\n",
      "- The boy is walking happily through the snow.\n",
      "- The boy is walking happily through the park.\n",
      "T5 Outputs:\n",
      "park brake alarm fault detected:\n",
      "- park brake alarm fault detected\n",
      "- park brake alarm fault detected park brake alarm fault detected\n",
      "- park brake alarm fault detected park brake alarm fault detected park brake alarm fault\n",
      "- park brake alarm fault detected park brake alarm park brake alarm fault detected\n",
      "- park brake alarm fault detected park brake park brake alarm fault detected\n",
      "alarm fault in park brake system:\n",
      "- alarm fault in park brake system alarm fault in park brake system alarm fault\n",
      "- alarm fault in park brake system alarm fault in park brake system\n",
      "- park brake alarm fault in park brake system alarm fault in park brake system\n",
      "- park brake system alarm fault in park brake system alarm fault in park brake\n",
      "- alarm fault in park brake system.\n",
      "park brake has alarm fault:\n",
      "- parking brake has alarm fault\n",
      "- alarm fault alarm fault alarm fault alarm fault alarm fault alarm fault alarm\n",
      "- alarm fault alarm fault alarm fault alarm fault alarm fault alarm fault\n",
      "- parking brake has alarm fault parking brake has alarm fault\n",
      "- alarm fault alarm fault alarm fault alarm fault alarm fault\n",
      "park brake system shows alarm fault:\n",
      "- alarm fault alarm fault alarm fault alarm fault alarm fault alarm fault alarm\n",
      "- alarm fault alarm fault alarm fault alarm fault alarm fault alarm fault\n",
      "- alarm fault fault alarm fault alarm fault alarm fault alarm fault alarm fault\n",
      "- alarm fault alarm fault fault alarm fault alarm fault alarm fault alarm fault\n",
      "- alarm fault alarm fault alarm fault alarm fault alarm fault alarm fault\n",
      "alarm fault present in park brake:\n",
      "- alarm fault present in park brake alarm fault present in park brake alarm\n",
      "- park brake alarm fault present in park brake\n",
      "- park brake alarm fault present in park brake alarm fault present in park brake\n",
      "- alarm fault present in park brake alarm alarm fault present in park brake\n",
      "- alarm fault present in park brake alarm fault present in parking brake alarm\n",
      "The boy is walking happily on the street:\n",
      "- pavement.\n",
      "- carpet.\n",
      "- grass.\n",
      "- sidewalk.\n",
      "- paved path.\n",
      "Pegasus Outputs:\n",
      "park brake alarm fault detected:\n",
      "- The park brake alarm is malfunctioning.\n",
      "- The park brake alarm malfunctioned.\n",
      "- There is a park brake alarm.\n",
      "- The park brake alarm has a fault.\n",
      "- There is a park brake alarm fault.\n",
      "alarm fault in park brake system:\n",
      "- The park brake system has an alarm fault.\n",
      "- There is an alarm fault in the park brake system.\n",
      "- There was an alarm fault in the park brake system.\n",
      "- Park brake system has an alarm fault.\n",
      "- The park brake system had an alarm fault.\n",
      "park brake has alarm fault:\n",
      "- The park brake has an alarm.\n",
      "- There is an alarm fault in the park brake.\n",
      "- There is an alarm fault with the park brake.\n",
      "- The park brake has an alarm fault.\n",
      "- The park brake has a fault.\n",
      "park brake system shows alarm fault:\n",
      "- The park brake system has an alarm.\n",
      "- The park brake system has an alarm fault.\n",
      "- The park brake system has a fault.\n",
      "- The park brake system is malfunctioning.\n",
      "- The park brake system has an alarm malfunction.\n",
      "alarm fault present in park brake:\n",
      "- There is an alarm fault in the park brake.\n",
      "- The park brake has an alarm fault.\n",
      "- There is a fault in the park brake.\n",
      "- There was an alarm fault in the park brake.\n",
      "- There is a park brake alarm fault.\n",
      "The boy is walking happily on the street:\n",
      "- A boy is walking.\n",
      "- The boy is walking.\n",
      "- The boy is happy.\n",
      "- The boy is walking happily.\n",
      "- A boy is walking happily.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
    "\n",
    "bart_tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-large\")\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-large\")\n",
    "pegasus_tokenizer = PegasusTokenizer.from_pretrained(\"tuner007/pegasus_paraphrase\")\n",
    "pegasus_model = PegasusForConditionalGeneration.from_pretrained(\"tuner007/pegasus_paraphrase\")\n",
    "\n",
    "sentences = [\"park brake alarm fault detected\",\n",
    "             \"alarm fault in park brake system\",\n",
    "             \"park brake has alarm fault\",\n",
    "             \"park brake system shows alarm fault\",\n",
    "             \"alarm fault present in park brake\",\n",
    "             \"The boy is walking happily on the street\"]\n",
    "\n",
    "bart_outputs = model_paraphrase(bart_tokenizer, bart_model, sentences)\n",
    "t5_outputs = model_paraphrase(t5_tokenizer, t5_model, sentences)\n",
    "pegasus_outputs = model_paraphrase(pegasus_tokenizer, pegasus_model, sentences)\n",
    "\n",
    "print(\"BART Outputs:\")\n",
    "for sentence, outputs in bart_outputs.items():\n",
    "    print(f\"{sentence}:\")\n",
    "    for output in outputs:\n",
    "        print(f\"- {output}\")\n",
    "print(\"T5 Outputs:\")\n",
    "for sentence, outputs in t5_outputs.items():\n",
    "    print(f\"{sentence}:\")\n",
    "    for output in outputs:\n",
    "        print(f\"- {output}\")\n",
    "print(\"Pegasus Outputs:\")\n",
    "for sentence, outputs in pegasus_outputs.items():\n",
    "    print(f\"{sentence}:\")\n",
    "    for output in outputs:\n",
    "        print(f\"- {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load contractions {expand: [contractions]}\n",
    "contractions = load_dictionary('data/Corrections/contractions.csv')\n",
    "\n",
    "# Introduce contractions in a sentence\n",
    "def introduce_contractions(sentence, chance=0.5):\n",
    "    for key, values in contractions.items():\n",
    "        if key in sentence and random.random() < chance:\n",
    "            sentence = sentence.replace(key, random.choice(values))\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pump is not working    -> pump is not working\n",
      "air horn does not work -> air horn doesn't work\n",
      "machine will not start -> machine will not start\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"pump is not working\",\n",
    "             \"air horn does not work\",\n",
    "             \"machine will not start\"]\n",
    "spacing = len(max(sentences, key=len))\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(\"{:<{}} -> {}\".format(sentence, spacing, introduce_contractions(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce Jargon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load abbreviations {original: [variations]}\n",
    "abbreviations = load_dictionary('data/Corrections/abbreviations.csv')\n",
    "\n",
    "# Introduce abbreviations in a sentence\n",
    "def introduce_abbreviations(sentence, chance=0.3):\n",
    "    for key, values in abbreviations.items():\n",
    "        if key in sentence and random.random() < chance:\n",
    "            sentence = sentence.replace(key, random.choice(values))\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pump is not working                          -> pmp is not working\n",
      "blown o-ring on left hand lift cylinder      -> blown 0-ring on l/ hand lift cylinder\n",
      "compressor oil pressure switch unserviceable -> compress oil press switch unserviceable\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"pump is not working\",\n",
    "             \"blown o-ring on left hand lift cylinder\",\n",
    "             \"compressor oil pressure switch unserviceable\"]\n",
    "spacing = len(max(sentences, key=len))\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(\"{:<{}} -> {}\".format(sentence, spacing, introduce_abbreviations(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce Typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "park brake alram fault detected\n",
      "alrm fault in park brake system\n",
      "park brake has alrm fault\n",
      "park brake sistem shows alarm fault\n",
      "alrm fault present in park brake\n"
     ]
    }
   ],
   "source": [
    "def introduce_typos(openai, sentence):\n",
    "    prompt = f\"Introduce at least one typo in the following sentence: {sentence}\"\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You make spelling mistakes in the given sentences.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.9,\n",
    "        top_p=0.9,\n",
    "        n=1\n",
    "    )\n",
    "\n",
    "    for choice in response.choices:\n",
    "        output = choice.message.content\n",
    "    return output\n",
    "\n",
    "for sentence in sentences:\n",
    "    out = introduce_typos(client, sentence)\n",
    "    print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
