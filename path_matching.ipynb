{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and Connect to Neo4j instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "from path_queries import direct_queries, complex_queries, get_connect_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for list of dictionaries to json file\n",
    "def list_to_json(data, json_file):\n",
    "    \"\"\" Save list of dictionaries to json file \"\"\"\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(data, indent=4))\n",
    "\n",
    "# Function to get entity type\n",
    "def get_entity_type(properties):\n",
    "    \"\"\" Construct entity class/subclass from properties \"\"\"\n",
    "    entity_type = properties[\"type\"]\n",
    "    if \"subtype0\" in properties:\n",
    "        entity_type += \"/\" + properties[\"subtype0\"]\n",
    "    if \"subtype1\" in properties:\n",
    "        entity_type += \"/\" + properties[\"subtype1\"]\n",
    "    return entity_type\n",
    "\n",
    "# Function to get entity information\n",
    "def get_entity_info(record, entity):\n",
    "    \"\"\" Extract entity information from record \"\"\"\n",
    "    properties = record[f\"{entity}_properties\"]\n",
    "    return {\n",
    "        \"name\": properties[\"text\"],\n",
    "        \"type\": get_entity_type(properties),\n",
    "        \"entry_id\": properties[\"entry_id\"]\n",
    "    }\n",
    "\n",
    "# Function to remove duplicate paths\n",
    "def remove_duplicates(paths):\n",
    "    \"\"\" Remove duplicate paths \"\"\"\n",
    "    unique_paths = []\n",
    "    for path in paths:\n",
    "        if path not in unique_paths:\n",
    "            unique_paths.append(path)\n",
    "    return unique_paths\n",
    "\n",
    "# Function to check validity of paths (if entities come from same entry)\n",
    "def check_validity(object, event, helper=None):\n",
    "    \"\"\" Check if entities come from same entry \"\"\"\n",
    "    object_set = set(object[\"entry_id\"])\n",
    "    event_set = set(event[\"entry_id\"])\n",
    "    # Check if there is a common entry_id\n",
    "    if helper:\n",
    "        helper_set = set(helper[\"entry_id\"])\n",
    "        common = object_set & event_set & helper_set\n",
    "    else:\n",
    "        common = object_set & event_set\n",
    "    return bool(common)\n",
    "\n",
    "# Function to print count of paths (valid and alternate paths)\n",
    "def print_path_counts(query, paths):\n",
    "    \"\"\" Print count of paths (valid and alternate paths) \"\"\"\n",
    "    num_direct, valid_direct = 0, 0\n",
    "    num_alternate, valid_alternate = 0, 0\n",
    "    for path in paths:\n",
    "        if path['alternate']:\n",
    "            num_alternate += 1\n",
    "            if path['valid']:\n",
    "                valid_alternate += 1\n",
    "        else:\n",
    "            num_direct += 1\n",
    "            if path['valid']:\n",
    "                valid_direct += 1\n",
    "    total_paths = num_direct + num_alternate\n",
    "    total_valid = valid_direct + valid_alternate\n",
    "\n",
    "    print(query[\"outfile\"])\n",
    "    print(f\"{'Direct':<10}{num_direct:<6} ({valid_direct:<3} valid)\")\n",
    "    print(f\"{'Alternate':<10}{num_alternate:<6} ({valid_alternate:<3} valid)\")\n",
    "    print(f\"{'Total':<10}{total_paths:<6} ({total_valid:<3} valid)\")\n",
    "    print(f\"{'-' * 30}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Matching Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get relation information\n",
    "def get_alternate_paths(query, record, object, connect_objects, event, valid, helper=None):\n",
    "    \"\"\" Extract relation information from record \"\"\"\n",
    "    alternate_paths = []\n",
    "    \n",
    "    # If PhysicalObject has connect relations to other PhysicalObjects\n",
    "    # connect_relations: hasPart, contains\n",
    "    for connect_obj in connect_objects:\n",
    "        # Ignore connect relations with more than 3 objects\n",
    "        if len(connect_obj) > 2:\n",
    "            continue\n",
    "        current_obj = object[\"name\"]\n",
    "        for obj in connect_obj:\n",
    "            current_obj = f\"{obj} {current_obj}\"\n",
    "            path = {\n",
    "                \"object_type\": object['type'],\n",
    "                \"object_name\": current_obj,\n",
    "                \"event_relation\": query[\"relation\"],\n",
    "                \"event_type\": event['type'],\n",
    "                \"event_name\": event['name'],\n",
    "            }\n",
    "            if helper:\n",
    "                path[\"helper_type\"] = helper['type']\n",
    "                path[\"helper_name\"] = helper['name']\n",
    "            path[\"valid\"] = valid\n",
    "            path['alternate'] = True\n",
    "            alternate_paths.append(path)\n",
    "\n",
    "    # If PhysicalObject has substitute relations to other PhysicalObjects\n",
    "    # substitute_relations: isA\n",
    "    for substitute_obj in record[\"substitute_objects\"]:\n",
    "        path = {\n",
    "            \"object_type\": get_entity_type(substitute_obj),\n",
    "            \"object_name\": substitute_obj['text'],\n",
    "            \"event_relation\": query[\"relation\"],\n",
    "            \"event_type\": event['type'],\n",
    "            \"event_name\": event['name']\n",
    "        }\n",
    "        if helper:\n",
    "            path[\"helper_type\"] = helper['type']\n",
    "            path[\"helper_name\"] = helper['name']\n",
    "        path[\"valid\"] = valid\n",
    "        path['alternate'] = True\n",
    "        alternate_paths.append(path)\n",
    "\n",
    "    # If Event has substitute relations to its own Events (Property, Process, State\n",
    "    # event_substitute: isA\n",
    "    for substitute_event in record[f\"substitute_{query['event']}\"]:\n",
    "        path = {\n",
    "            \"object_type\": object['type'],\n",
    "            \"object_name\": object['name'],\n",
    "            \"event_relation\": query[\"relation\"],\n",
    "            \"event_type\": get_entity_type(substitute_event),\n",
    "            \"event_name\": substitute_event['text']\n",
    "        }\n",
    "        if helper:\n",
    "            path[\"helper_type\"] = helper['type']\n",
    "            path[\"helper_name\"] = helper['name']\n",
    "        path[\"valid\"] = valid\n",
    "        path['alternate'] = True\n",
    "        alternate_paths.append(path)\n",
    "\n",
    "    alternate_paths = remove_duplicates(alternate_paths)\n",
    "    return alternate_paths\n",
    "\n",
    "# Function to process query results\n",
    "def process_query_results(query, results, paths, complex=False):\n",
    "    \"\"\" Process query results and extract relevant information \"\"\"\n",
    "\n",
    "    for record in results:\n",
    "        # PhysicalObject - Equipment\n",
    "        object_info = get_entity_info(record, \"object\")\n",
    "        connect_objects = get_connect_objects(DRIVER, object_info[\"name\"])\n",
    "\n",
    "        # Property / Process / State - Undesirable event\n",
    "        event_info = get_entity_info(record, query[\"event\"])\n",
    "\n",
    "        path = {\n",
    "            \"object_type\": object_info[\"type\"],\n",
    "            \"object_name\": object_info[\"name\"],\n",
    "            \"event_relation\": query[\"relation\"],\n",
    "            \"event_type\": event_info[\"type\"],\n",
    "            \"event_name\": event_info[\"name\"],\n",
    "        }\n",
    "\n",
    "        # If complex (there are helper entities that describe Undesirable event)\n",
    "        if complex:\n",
    "            helper_info = get_entity_info(record, query[\"helper\"])\n",
    "            path[\"helper_type\"] = helper_info[\"type\"]\n",
    "            path[\"helper_name\"] = helper_info[\"name\"]\n",
    "            # Check if path is confirmed valid (entities come from same entry)\n",
    "            path[\"valid\"] = check_validity(object_info, event_info, helper_info)\n",
    "        else:\n",
    "            # Check if path is confirmed valid (entities come from same entry)\n",
    "            path[\"valid\"] = check_validity(object_info, event_info)\n",
    "\n",
    "        path['alternate'] = False\n",
    "\n",
    "        # Alternate paths (if PhysicalObject has connect or substitute relations)\n",
    "        if complex: # Pass helper_info in generating alternate paths if complex\n",
    "            alternate_paths = get_alternate_paths(query, record, object_info, connect_objects, event_info, path['valid'], helper_info)\n",
    "        else:       # No helper_info if not complex\n",
    "            alternate_paths = get_alternate_paths(query, record, object_info, connect_objects, event_info, path['valid'])\n",
    "\n",
    "        # Include paths only if they don't already exist\n",
    "        potential_paths = [path] + alternate_paths\n",
    "        for p in potential_paths:\n",
    "            if p not in paths:\n",
    "                paths.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run to extract paths from Neo4j instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object_property_paths\n",
      "Direct    26     (26  valid)\n",
      "Alternate 23     (23  valid)\n",
      "Total     49     (49  valid)\n",
      "------------------------------\n",
      "process_agent_paths\n",
      "Direct    77     (77  valid)\n",
      "Alternate 314    (314 valid)\n",
      "Total     391    (391 valid)\n",
      "------------------------------\n",
      "process_patient_paths\n",
      "Direct    38     (38  valid)\n",
      "Alternate 231    (231 valid)\n",
      "Total     269    (269 valid)\n",
      "------------------------------\n",
      "state_patient_paths\n",
      "Direct    293    (293 valid)\n",
      "Alternate 915    (915 valid)\n",
      "Total     1208   (1208 valid)\n",
      "------------------------------\n",
      "object_property_state_paths\n",
      "Direct    1      (1   valid)\n",
      "Alternate 2      (2   valid)\n",
      "Total     3      (3   valid)\n",
      "------------------------------\n",
      "object_process_state_paths\n",
      "Direct    0      (0   valid)\n",
      "Alternate 0      (0   valid)\n",
      "Total     0      (0   valid)\n",
      "------------------------------\n",
      "state_agent_activity_paths\n",
      "Direct    146    (25  valid)\n",
      "Alternate 865    (111 valid)\n",
      "Total     1011   (136 valid)\n",
      "------------------------------\n",
      "state_agent_patient_paths\n",
      "Direct    42     (7   valid)\n",
      "Alternate 207    (24  valid)\n",
      "Total     249    (31  valid)\n",
      "------------------------------\n",
      "process_agent_patient_paths\n",
      "Direct    460    (31  valid)\n",
      "Alternate 1990   (119 valid)\n",
      "Total     2450   (150 valid)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Connect to Neo4j\n",
    "URI = \"bolt://localhost:7687\"\n",
    "USERNAME = \"neo4j\"\n",
    "PASSWORD = \"password\"\n",
    "DRIVER = GraphDatabase.driver(URI, auth=(USERNAME, PASSWORD))\n",
    "OUTPATH = \"path_patterns/\"\n",
    "\n",
    "with DRIVER.session() as session:\n",
    "    for query in direct_queries:\n",
    "        results = session.run(query[\"query\"])\n",
    "        paths = []\n",
    "        process_query_results(query, results, paths, complex=False)\n",
    "        print_path_counts(query, paths)\n",
    "        list_to_json(paths, f\"{OUTPATH}{query['outfile']}.json\")\n",
    "\n",
    "    for query in complex_queries:\n",
    "        results = session.run(query[\"query\"])\n",
    "        paths = []\n",
    "        process_query_results(query, results, paths, complex=True)\n",
    "        print_path_counts(query, paths)\n",
    "        list_to_json(paths, f\"{OUTPATH}{query['outfile']}.json\")\n",
    "\n",
    "DRIVER.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\tpaths in object_property_paths\n",
      "391\tpaths in process_agent_paths\n",
      "269\tpaths in process_patient_paths\n",
      "1208\tpaths in state_patient_paths\n",
      "3\tpaths in object_property_state_paths\n",
      "0\tpaths in object_process_state_paths\n",
      "136\tpaths in state_agent_activity_paths\n",
      "31\tpaths in state_agent_patient_paths\n",
      "150\tpaths in process_agent_patient_paths\n",
      "Total number of paths: 2237\n"
     ]
    }
   ],
   "source": [
    "from llm_generation import get_all_paths\n",
    "\n",
    "# Get all paths\n",
    "all_paths = get_all_paths(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Validated Path Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read human validated unconfirmed paths\n",
    "def read_paths_validated(filepath=\"path_patterns/paths_to_validate.csv\"):\n",
    "    \"\"\" Read csv file and extract human validated paths \"\"\"\n",
    "    # Store validated paths in dictionary\n",
    "    yes_paths, no_paths, unsure_paths = {}, [], []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader) # Ignore header\n",
    "        for row in reader:\n",
    "            if row[0].endswith(\"PATHS\"):\n",
    "                pathtype = row[0].lower()\n",
    "                yes_paths[pathtype] = []\n",
    "            else:\n",
    "                if row[3].lower() == 'y':\n",
    "                    yes_paths[pathtype].append({\n",
    "                        \"object_name\": row[0],\n",
    "                        \"event_name\": row[1],\n",
    "                        \"helper_name\": row[2],\n",
    "                        \"valid\": True\n",
    "                    })\n",
    "                elif row[3].lower() == 'n':\n",
    "                    no_paths.append([row[0], row[1], row[2]])\n",
    "                elif row[3].lower() == '?':\n",
    "                    unsure_paths.append([row[0], row[1], row[2]])\n",
    "    print(f\"Extracted validated paths from '{filepath}'\")\n",
    "    num_yes = sum(len(value) for value in yes_paths.values())\n",
    "    print(f\"Number of y paths: {num_yes}\")\n",
    "    print(f\"Number of n paths: {len(no_paths)}\")\n",
    "    print(f\"Number of ? paths: {len(unsure_paths)}\")\n",
    "    return yes_paths, no_paths, unsure_paths\n",
    "\n",
    "# Function to update path json files with human validated unconfirmed paths\n",
    "def update_paths_validated(valid_paths):\n",
    "    \"\"\" Update path json files with human validated unconfirmed paths \"\"\"\n",
    "    # For each path type, open json file and update the fields\n",
    "    for pathtype, paths in valid_paths.items():\n",
    "        num_updated = 0\n",
    "        pathname = f\"path_patterns/{pathtype}.json\"\n",
    "        pathfile = open(pathname, \"r\", encoding=\"utf-8\")\n",
    "        pathdata = json.load(pathfile)\n",
    "        pathfile.close()\n",
    "        for i, path in enumerate(pathdata):\n",
    "            if not path['valid'] and not path['alternate']:\n",
    "                for valid in paths:\n",
    "                    if (path['object_name'] == valid['object_name'] and\n",
    "                        path['event_name'] == valid['event_name'] and\n",
    "                        path['helper_name'] == valid['helper_name']):\n",
    "                        path['valid'] = True\n",
    "                        num_updated += 1\n",
    "                        for j in range(i+1, len(pathdata)):\n",
    "                            if pathdata[j]['alternate'] is True:\n",
    "                                pathdata[j]['valid'] = True\n",
    "                                num_updated += 1\n",
    "                            else:\n",
    "                                break\n",
    "        list_to_json(pathdata, pathname)\n",
    "        print(f\"{num_updated} paths updated in '{pathname}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run to update validated paths from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted validated paths from 'path_patterns/paths_to_validate_mh.csv'\n",
      "Number of y paths: 151\n",
      "Number of n paths: 428\n",
      "Number of ? paths: 6\n",
      "471 paths updated in 'path_patterns/state_agent_activity_paths.json'\n",
      "6 paths updated in 'path_patterns/state_agent_patient_paths.json'\n",
      "1078 paths updated in 'path_patterns/process_agent_patient_paths.json'\n"
     ]
    }
   ],
   "source": [
    "paths_to_validate = 'path_patterns/paths_to_validate_mh.csv'\n",
    "valid_paths, _, _ = read_paths_validated(paths_to_validate)\n",
    "update_paths_validated(valid_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
