{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and Connect to Neo4j instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "from path_queries import direct_queries, complex_queries, get_connect_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for list of dictionaries to json file\n",
    "def list_to_json(data, json_file):\n",
    "    \"\"\" Save list of dictionaries to json file \"\"\"\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(data, indent=4))\n",
    "\n",
    "# Function to get entity type\n",
    "def get_entity_type(properties):\n",
    "    \"\"\" Construct entity class/subclass from properties \"\"\"\n",
    "    entity_type = properties[\"type\"]\n",
    "    if \"subtype0\" in properties:\n",
    "        entity_type += \"/\" + properties[\"subtype0\"]\n",
    "    if \"subtype1\" in properties:\n",
    "        entity_type += \"/\" + properties[\"subtype1\"]\n",
    "    return entity_type\n",
    "\n",
    "# Function to get entity information\n",
    "def get_entity_info(record, entity):\n",
    "    \"\"\" Extract entity information from record \"\"\"\n",
    "    properties = record[f\"{entity}_properties\"]\n",
    "    return {\n",
    "        \"name\": properties[\"text\"],\n",
    "        \"type\": get_entity_type(properties),\n",
    "        \"entry_id\": properties[\"entry_id\"]\n",
    "    }\n",
    "\n",
    "# Function to remove duplicate paths\n",
    "def remove_duplicates(paths):\n",
    "    \"\"\" Remove duplicate paths \"\"\"\n",
    "    unique_paths = []\n",
    "    for path in paths:\n",
    "        if path not in unique_paths:\n",
    "            unique_paths.append(path)\n",
    "    return unique_paths\n",
    "\n",
    "# Function to check validity of paths (if entities come from same entry)\n",
    "def check_validity(object, event, helper=None):\n",
    "    \"\"\" Check if entities come from same entry \"\"\"\n",
    "    object_set = set(object[\"entry_id\"])\n",
    "    event_set = set(event[\"entry_id\"])\n",
    "    # Check if there is a common entry_id\n",
    "    if helper:\n",
    "        helper_set = set(helper[\"entry_id\"])\n",
    "        common = object_set & event_set & helper_set\n",
    "    else:\n",
    "        common = object_set & event_set\n",
    "    return bool(common)\n",
    "\n",
    "# Function to print count of paths (valid and alternate paths)\n",
    "def print_path_counts(query, paths):\n",
    "    \"\"\" Print count of paths (valid and alternate paths) \"\"\"\n",
    "    num_direct, valid_direct = 0, 0\n",
    "    num_alternate, valid_alternate = 0, 0\n",
    "    for path in paths:\n",
    "        if path['alternate']:\n",
    "            num_alternate += 1\n",
    "            if path['valid']:\n",
    "                valid_alternate += 1\n",
    "        else:\n",
    "            num_direct += 1\n",
    "            if path['valid']:\n",
    "                valid_direct += 1\n",
    "    total_paths = num_direct + num_alternate\n",
    "    total_valid = valid_direct + valid_alternate\n",
    "\n",
    "    print(query[\"outfile\"])\n",
    "    print(f\"{'Direct':<10}{num_direct:<6} ({valid_direct:<3} valid)\")\n",
    "    print(f\"{'Alternate':<10}{num_alternate:<6} ({valid_alternate:<3} valid)\")\n",
    "    print(f\"{'Total':<10}{total_paths:<6} ({total_valid:<3} valid)\")\n",
    "    print(f\"{'-' * 30}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Matching Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get relation information\n",
    "def get_alternate_paths(query, record, object, connect_objects, event, valid, event_helper=None, helper=None):\n",
    "    \"\"\" Extract relation information from record \"\"\"\n",
    "    alternate_paths = []\n",
    "    \n",
    "    # If PhysicalObject has connect relations to other PhysicalObjects\n",
    "    # connect_relations: hasPart, contains\n",
    "    for connect_obj in connect_objects:\n",
    "        # steering pump hose, pump hose, hose \n",
    "        if len(connect_obj) > 2:\n",
    "            continue\n",
    "        current_obj = object[\"name\"]\n",
    "        for obj in connect_obj:\n",
    "            current_obj = f\"{obj} {current_obj}\"\n",
    "            path = {\"object_name\": current_obj}\n",
    "            if event_helper is not None:\n",
    "                path['event_name'] = event_helper\n",
    "            else:\n",
    "                path['event_name'] = event['name']\n",
    "            path[\"valid\"] = valid\n",
    "            path['alternate'] = True\n",
    "            alternate_paths.append(path)\n",
    "\n",
    "    # If PhysicalObject has substitute relations to other PhysicalObjects\n",
    "    # substitute_relations: isA\n",
    "    for substitute_obj in record[\"substitute_objects\"]:\n",
    "        path = {\"object_name\": substitute_obj['text']}\n",
    "        if event_helper is not None:\n",
    "            path['event_name'] = event_helper\n",
    "        else:\n",
    "            path['event_name'] = event['name']\n",
    "        path[\"valid\"] = valid\n",
    "        path['alternate'] = True\n",
    "        alternate_paths.append(path)\n",
    "\n",
    "    # If Event has substitute relations to its own Events (Property, Process, State\n",
    "    # event_substitute: isA\n",
    "    for substitute_event in record[f\"substitute_{query['event']}\"]:\n",
    "        path = {\"object_name\": object['name']}\n",
    "        if event_helper is not None and helper is not None:\n",
    "            if query['outfile'] == 'object_property_state_paths':\n",
    "                # e.g. no charge\n",
    "                event_name = f\"{helper['name']} {substitute_event['text']}\"\n",
    "            else:\n",
    "                # e.g. leak fuel\n",
    "                event_name = f\"{substitute_event['text']} {helper['name']}\"\n",
    "            path['event_name'] = event_name\n",
    "        else:\n",
    "            path['event_name'] = substitute_event['text']\n",
    "        path[\"valid\"] = valid\n",
    "        path['alternate'] = True\n",
    "        alternate_paths.append(path)\n",
    "\n",
    "    alternate_paths = remove_duplicates(alternate_paths)\n",
    "    return alternate_paths\n",
    "\n",
    "# Function to process query results\n",
    "def process_query_results(query, results, paths, complex=False):\n",
    "    \"\"\" Process query results and extract relevant information \"\"\"\n",
    "\n",
    "    for record in results:\n",
    "        # PhysicalObject - Equipment\n",
    "        object_info = get_entity_info(record, \"object\")\n",
    "        connect_objects = get_connect_objects(DRIVER, object_info[\"name\"])\n",
    "        object_name = object_info[\"name\"]\n",
    "\n",
    "        # Property / Process / State - Undesirable event\n",
    "        event_info = get_entity_info(record, query[\"event\"])\n",
    "        event_name = event_info[\"name\"]    \n",
    "\n",
    "        # Helper entity (if complex query)\n",
    "        helper_info = None\n",
    "        if complex:\n",
    "            helper_info = get_entity_info(record, query[\"helper\"]) # event_info[\"type\"]\n",
    "            if query['outfile'] == 'object_property_state_paths':\n",
    "                # e.g. no charge\n",
    "                event_name = f\"{helper_info['name']} {event_info['name']}\"\n",
    "            else:\n",
    "                # e.g. leak fuel\n",
    "                event_name = f\"{event_info['name']} {helper_info['name']}\"\n",
    "\n",
    "        # Construct path\n",
    "        path = {\n",
    "            \"object_name\": object_name,\n",
    "            \"event_name\": event_name,\n",
    "        }\n",
    "        \n",
    "        # Check if path is confirmed valid (entities come from same entry)\n",
    "        path[\"valid\"] = check_validity(object_info, event_info, helper=None if not complex else helper_info)\n",
    "        \n",
    "        path['alternate'] = False # Not an alternate path\n",
    "\n",
    "        # Alternate paths (if PhysicalObject has connect or substitute relations)\n",
    "        if complex: # Pass helper_info in generating alternate paths if complex\n",
    "            alternate_paths = get_alternate_paths(query, record, object_info, connect_objects, event_info, path['valid'], \n",
    "                                                  event_helper=event_name, helper=helper_info)\n",
    "        else:       # No helper_info if not complex\n",
    "            alternate_paths = get_alternate_paths(query, record, object_info, connect_objects, event_info, path['valid'])\n",
    "\n",
    "        # Include paths only if they don't already exist\n",
    "        potential_paths = [path] + alternate_paths\n",
    "        for p in potential_paths:\n",
    "            if p not in paths:\n",
    "                paths.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run to extract paths from Neo4j instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object_property_paths\n",
      "Direct    26     (26  valid)\n",
      "Alternate 23     (23  valid)\n",
      "Total     49     (49  valid)\n",
      "------------------------------\n",
      "process_agent_paths\n",
      "Direct    77     (77  valid)\n",
      "Alternate 314    (314 valid)\n",
      "Total     391    (391 valid)\n",
      "------------------------------\n",
      "process_patient_paths\n",
      "Direct    38     (38  valid)\n",
      "Alternate 231    (231 valid)\n",
      "Total     269    (269 valid)\n",
      "------------------------------\n",
      "state_patient_paths\n",
      "Direct    293    (293 valid)\n",
      "Alternate 915    (915 valid)\n",
      "Total     1208   (1208 valid)\n",
      "------------------------------\n",
      "object_property_state_paths\n",
      "Direct    1      (1   valid)\n",
      "Alternate 2      (2   valid)\n",
      "Total     3      (3   valid)\n",
      "------------------------------\n",
      "object_process_state_paths\n",
      "Direct    0      (0   valid)\n",
      "Alternate 0      (0   valid)\n",
      "Total     0      (0   valid)\n",
      "------------------------------\n",
      "state_agent_activity_paths\n",
      "Direct    146    (25  valid)\n",
      "Alternate 865    (111 valid)\n",
      "Total     1011   (136 valid)\n",
      "------------------------------\n",
      "state_agent_patient_paths\n",
      "Direct    42     (7   valid)\n",
      "Alternate 207    (24  valid)\n",
      "Total     249    (31  valid)\n",
      "------------------------------\n",
      "process_agent_patient_paths\n",
      "Direct    460    (31  valid)\n",
      "Alternate 1990   (119 valid)\n",
      "Total     2450   (150 valid)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Connect to Neo4j\n",
    "URI = \"bolt://localhost:7687\"\n",
    "USERNAME = \"neo4j\"\n",
    "PASSWORD = \"password\"\n",
    "DRIVER = GraphDatabase.driver(URI, auth=(USERNAME, PASSWORD))\n",
    "OUTPATH = \"path_patterns/\"\n",
    "\n",
    "with DRIVER.session() as session:\n",
    "    for query in direct_queries:\n",
    "        results = session.run(query[\"query\"])\n",
    "        paths = []\n",
    "        process_query_results(query, results, paths, complex=False)\n",
    "        print_path_counts(query, paths)\n",
    "        list_to_json(paths, f\"{OUTPATH}{query['outfile']}.json\")\n",
    "\n",
    "    for query in complex_queries:\n",
    "        results = session.run(query[\"query\"])\n",
    "        paths = []\n",
    "        process_query_results(query, results, paths, complex=True)\n",
    "        print_path_counts(query, paths)\n",
    "        list_to_json(paths, f\"{OUTPATH}{query['outfile']}.json\")\n",
    "\n",
    "DRIVER.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\tpaths in object_property_paths\n",
      "391\tpaths in process_agent_paths\n",
      "269\tpaths in process_patient_paths\n",
      "1208\tpaths in state_patient_paths\n",
      "3\tpaths in object_property_state_paths\n",
      "0\tpaths in object_process_state_paths\n",
      "607\tpaths in state_agent_activity_paths\n",
      "37\tpaths in state_agent_patient_paths\n",
      "1228\tpaths in process_agent_patient_paths\n",
      "Total number of paths: 3792\n"
     ]
    }
   ],
   "source": [
    "from llm_generate import get_all_paths\n",
    "\n",
    "# Get all valid paths\n",
    "all_paths, _ = get_all_paths(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Validated Path Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract invalid paths for human validation\n",
    "def prepare_path_for_validation():\n",
    "    \"\"\" Extract paths that are not confirmed valid for human validation in csv file. \"\"\"\n",
    "    queries = direct_queries + complex_queries\n",
    "    requires_validation = {}\n",
    "    for query in queries:\n",
    "        with open(f\"path_patterns/{query['outfile']}.json\", encoding='utf-8') as f:\n",
    "            requires_validation[query['outfile']] = []\n",
    "            data = json.load(f)\n",
    "            for path in data:\n",
    "                # If path does not come from entry and is not an alternate path\n",
    "                if not path['valid'] and not path['alternate']:\n",
    "                    requires_validation[query['outfile']].append({\n",
    "                        \"Physical Object\": path['object_name'],\n",
    "                        \"Undesirable Event\": path['event_name'],\n",
    "                        \"Helper PO/Event\": path['helper_name'] if 'helper_name' in path else \"\",\n",
    "                        \"Valid\": \"\"\n",
    "                    })\n",
    "\n",
    "    # Only keep path types that require validation\n",
    "    requires_validation = {k: v for k, v in requires_validation.items() if v}\n",
    "                    \n",
    "    # Save into csv file with headers = [PhysicalObject,UndesirableEvent,Valid]\n",
    "    # where Valid is to be filled by human with x if valid, and empty if invalid\n",
    "    with open(\"path_patterns/paths_to_validate.csv\", \"w\", encoding='utf-8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"Physical Object\", \"Undesirable Event\", \"Helper PO/Event\", \"Valid\"])\n",
    "        writer.writeheader()\n",
    "        for pathtype, paths in requires_validation.items():\n",
    "            writer.writerow({\"Physical Object\": pathtype.upper(), \"Undesirable Event\": \"\", \"Helper PO/Event\": \"\", \"Valid\": \"\"})\n",
    "            for path in paths:\n",
    "                writer.writerow(path)\n",
    "\n",
    "# Function to read human validated unconfirmed paths\n",
    "def read_paths_validated(filepath=\"path_patterns/paths_to_validate.csv\"):\n",
    "    \"\"\" Read csv file and extract human validated paths \"\"\"\n",
    "    # Store validated paths in dictionary\n",
    "    yes_paths, no_paths, unsure_paths = {}, [], []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader) # Ignore header\n",
    "        for row in reader:\n",
    "            if row[0].endswith(\"PATHS\"):\n",
    "                pathtype = row[0].lower()\n",
    "                yes_paths[pathtype] = []\n",
    "            else:\n",
    "                if row[3].lower() == 'y':\n",
    "                    yes_paths[pathtype].append({\n",
    "                        \"object_name\": row[0],\n",
    "                        \"event_name1\": f\"{row[1]} {row[2]}\",\n",
    "                        \"event_name2\": f\"{row[2]} {row[1]}\",\n",
    "                        \"valid\": True\n",
    "                    })\n",
    "                elif row[3].lower() == 'n':\n",
    "                    no_paths.append([row[0], row[1], row[2]])\n",
    "                elif row[3].lower() == '?':\n",
    "                    unsure_paths.append([row[0], row[1], row[2]])\n",
    "    print(f\"Extracted validated paths from '{filepath}'\")\n",
    "    num_yes = sum(len(value) for value in yes_paths.values())\n",
    "    print(f\"Number of y paths: {num_yes}\")\n",
    "    print(f\"Number of n paths: {len(no_paths)}\")\n",
    "    print(f\"Number of ? paths: {len(unsure_paths)}\")\n",
    "    return yes_paths, no_paths, unsure_paths\n",
    "\n",
    "# Function to update path json files with human validated unconfirmed paths\n",
    "def update_paths_validated(valid_paths):\n",
    "    \"\"\" Update path json files with human validated unconfirmed paths \"\"\"\n",
    "    # For each path type, open json file and update the fields\n",
    "    for pathtype, paths in valid_paths.items():\n",
    "        num_updated = 0\n",
    "        pathname = f\"path_patterns/{pathtype}.json\"\n",
    "        pathfile = open(pathname, \"r\", encoding=\"utf-8\")\n",
    "        pathdata = json.load(pathfile)\n",
    "        pathfile.close()\n",
    "        for i, path in enumerate(pathdata):\n",
    "            if not path['valid'] and not path['alternate']:\n",
    "                for valid in paths:\n",
    "                    if (path['object_name'] == valid['object_name'] and\n",
    "                        (path['event_name'] == valid['event_name1'] or\n",
    "                         path['event_name'] == valid['event_name2'])):\n",
    "                        path['valid'] = True\n",
    "                        num_updated += 1\n",
    "                        for j in range(i+1, len(pathdata)):\n",
    "                            if pathdata[j]['alternate'] is True:\n",
    "                                pathdata[j]['valid'] = True\n",
    "                                num_updated += 1\n",
    "                            else:\n",
    "                                break\n",
    "        list_to_json(pathdata, pathname)\n",
    "        print(f\"{num_updated} paths updated in '{pathname}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run to update validated paths from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to get paths to validate\n",
    "prepare_path_for_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted validated paths from 'path_patterns/paths_to_validate_mh.csv'\n",
      "Number of y paths: 151\n",
      "Number of n paths: 428\n",
      "Number of ? paths: 6\n",
      "0 paths updated in 'path_patterns/state_agent_activity_paths.json'\n",
      "0 paths updated in 'path_patterns/state_agent_patient_paths.json'\n",
      "0 paths updated in 'path_patterns/process_agent_patient_paths.json'\n",
      "\n",
      "Getting all updated valid paths...\n",
      "49\tpaths in object_property_paths\n",
      "391\tpaths in process_agent_paths\n",
      "269\tpaths in process_patient_paths\n",
      "1208\tpaths in state_patient_paths\n",
      "3\tpaths in object_property_state_paths\n",
      "0\tpaths in object_process_state_paths\n",
      "607\tpaths in state_agent_activity_paths\n",
      "37\tpaths in state_agent_patient_paths\n",
      "1228\tpaths in process_agent_patient_paths\n",
      "Total number of paths: 3792\n"
     ]
    }
   ],
   "source": [
    "# Run this to update validated paths\n",
    "paths_to_validate = 'path_patterns/paths_to_validate_mh.csv'\n",
    "valid_paths, _, _ = read_paths_validated(paths_to_validate)\n",
    "update_paths_validated(valid_paths)\n",
    "\n",
    "# Get all updated valid paths\n",
    "print(\"\\nGetting all updated valid paths...\")\n",
    "all_paths, _ = get_all_paths(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_events(paths):\n",
    "    \"\"\" Count number of events from paths \"\"\"\n",
    "    events = {}\n",
    "    combine = [\"fault\", \"leak\", \"crack\", \"blowing\", \"replac\", \"clean\"]\n",
    "    \n",
    "    for path in paths:\n",
    "        event = path['event_name']\n",
    "        for c in combine:\n",
    "            if c in event:\n",
    "                event = c\n",
    "        if event not in events:\n",
    "            events[event] = 1\n",
    "        else:\n",
    "            events[event] += 1\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "Event                Count\n",
      "crack                111\n",
      "noisy                9\n",
      "hole                 2\n",
      "leak                 1698\n",
      "weeping              63\n",
      "bypassing            3\n",
      "discharging          3\n",
      "creeping             2\n",
      "falling off          3\n",
      "movement             15\n",
      "going on and off     3\n",
      "overheating          2\n",
      "vibration            2\n",
      "bogging              1\n",
      "tripping out         6\n",
      "exhausting           3\n",
      "coming up            1\n",
      "running constantly   4\n",
      "blowing              28\n",
      "earthing out         6\n",
      "alarm                13\n",
      "emptying             14\n",
      "overgreasing         1\n",
      "not working          57\n",
      "unserviceable        241\n",
      "warm                 6\n",
      "plugged              5\n",
      "disconnected         2\n",
      "doesn't work         3\n",
      "fault                172\n",
      "stuck on             2\n",
      "working intermittently 2\n",
      "on                   24\n",
      "failed               19\n",
      "not charging         1\n",
      "overcharged          1\n",
      "error                7\n",
      "broken               172\n",
      "to be fixed          2\n",
      "blown                137\n",
      "out of service       3\n",
      "seized               17\n",
      "shot                 5\n",
      "missing              27\n",
      "bent                 2\n",
      "needs                4\n",
      "worn                 31\n",
      "temperature error    9\n",
      "popped               16\n",
      "worn out             1\n",
      "not reading          8\n",
      "damage               4\n",
      "flat                 1\n",
      "loose                7\n",
      "damaged              3\n",
      "slow                 1\n",
      "out                  15\n",
      "tripped              2\n",
      "out of date          2\n",
      "wired incorrectly    8\n",
      "won't start          1\n",
      "found                21\n",
      "excess play          5\n",
      "sounds continuously  3\n",
      "not meshing          1\n",
      "no                   11\n",
      "trip                 3\n",
      "not counting         2\n",
      "no excitation        1\n",
      "mismatched           1\n",
      "out of adjustment    7\n",
      "issues               1\n",
      "corroded             6\n",
      "no good              6\n",
      "fail                 2\n",
      "does not self assign 1\n",
      "no reception         2\n",
      "blocked              2\n",
      "snapped              11\n",
      "not cold             6\n",
      "dropped              2\n",
      "tight                9\n",
      "melted               3\n",
      "locked               1\n",
      "sticking             1\n",
      "low                  14\n",
      "shorted              3\n",
      "not communicating    1\n",
      "doesn't turn on      2\n",
      "no signal            2\n",
      "no charge            3\n",
      "needs fitting        68\n",
      "needs extending      66\n",
      "needs repair         79\n",
      "replac               238\n",
      "needs boost          6\n",
      "clean                92\n",
      "needs resealing      7\n",
      "need adjusting       19\n",
      "need change out      19\n",
      "need fitted          9\n",
      "requires testing     3\n",
      "requires tagging     1\n",
      "missing smoke detector 1\n",
      "needs loctite        21\n",
      "needs aerial         3\n",
      "found oil            2\n",
      "no grease            8\n",
      "blocked grass        1\n",
      "dropped cell         1\n",
      "bypassing air        2\n"
     ]
    }
   ],
   "source": [
    "# Count number of events from all paths\n",
    "events = count_events(all_paths)\n",
    "print(len(events))\n",
    "print(f\"{\"Event\":<20} Count\")\n",
    "for event, count in events.items():\n",
    "    print(f\"{event:<20} {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
